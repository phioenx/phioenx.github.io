<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>哈基鹏的大模型之旅（三） | 哈基鹏的博客🐦</title><meta name="author" content="PhoenixPeng"><meta name="copyright" content="PhoenixPeng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="简要介绍RAG的定义以及工作流、RAG开发框架LangChain和大模型开发流程。">
<meta property="og:type" content="article">
<meta property="og:title" content="哈基鹏的大模型之旅（三）">
<meta property="og:url" content="http://example.com/2025/10/30/4.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%89%EF%BC%89/index.html">
<meta property="og:site_name" content="哈基鹏的博客🐦">
<meta property="og:description" content="简要介绍RAG的定义以及工作流、RAG开发框架LangChain和大模型开发流程。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/cover4.jpg">
<meta property="article:published_time" content="2025-10-30T08:03:26.000Z">
<meta property="article:modified_time" content="2025-10-31T06:12:26.396Z">
<meta property="article:author" content="PhoenixPeng">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/cover4.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "哈基鹏的大模型之旅（三）",
  "url": "http://example.com/2025/10/30/4.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%89%EF%BC%89/",
  "image": "http://example.com/img/cover4.jpg",
  "datePublished": "2025-10-30T08:03:26.000Z",
  "dateModified": "2025-10-31T06:12:26.396Z",
  "author": [
    {
      "@type": "Person",
      "name": "PhoenixPeng",
      "url": "http://example.com"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/10/30/4.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%89%EF%BC%89/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '哈基鹏的大模型之旅（三）',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/modify.css"><link rel="stylesheet" href=" /css/custom.css"><meta name="generator" content="Hexo 8.1.0"></head><body><div id="web_bg" style="background-image: url(https://amadeuspjq.cn/img/background.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/cover4.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">哈基鹏的博客🐦</span></a><a class="nav-page-title" href="/"><span class="site-name">哈基鹏的大模型之旅（三）</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">哈基鹏的大模型之旅（三）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-10-30T08:03:26.000Z" title="发表于 2025-10-30 16:03:26">2025-10-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-10-31T06:12:26.396Z" title="更新于 2025-10-31 14:12:26">2025-10-31</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/LLM/">LLM</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img gist" style="background-image: url(/img/cover4.jpg)"></div><article class="container post-content" id="article-container"><h1 id="检索增强生成（RAG）"><a href="#检索增强生成（RAG）" class="headerlink" title="检索增强生成（RAG）"></a>检索增强生成（RAG）</h1><p><font color = black size = 4>大型语言模型（LLM）相较于传统的语言模型具有更强大的能力，然而在某些情况下，它们仍可能无法提供准确的答案。</font></p>
<p><font color = black size = 4>目前 LLM 面临的主要问题有：</font></p>
<ul>
<li><font color = black size = 4><strong>信息偏差&#x2F;幻觉：</strong> LLM 有时会产生与客观事实不符的信息，导致用户接收到的信息不准确。RAG 通过检索数据源，辅助模型生成过程，确保输出内容的精确性和可信度，减少信息偏差。</font></li>
<li><font color = black size = 4><strong>知识更新滞后性：</strong> LLM 基于静态的数据集训练，这可能导致模型的知识更新滞后，无法及时反映最新的信息动态。RAG 通过实时检索最新数据，保持内容的时效性，确保信息的持续更新和准确性。</font></li>
<li><font color = black size = 4><strong>内容不可追溯：</strong> LLM 生成的内容往往缺乏明确的信息来源，影响内容的可信度。RAG 将生成内容与检索到的原始资料建立链接，增强了内容的可追溯性，从而提升了用户对生成内容的信任度。</font></li>
<li><font color = black size = 4><strong>领域专业知识能力欠缺：</strong> LLM 在处理特定领域的专业知识时，效果可能不太理想，这可能会影响到其在相关领域的回答质量。RAG 通过检索特定领域的相关文档，为模型提供丰富的上下文信息，从而提升了在专业领域内的问题回答质量和深度。</font></li>
<li><font color = black size = 4><strong>推理能力限制：</strong> 面对复杂问题时，LLM 可能缺乏必要的推理能力，这影响了其对问题的理解和回答。RAG 结合检索到的信息和模型的生成能力，通过提供额外的背景知识和数据支持，增强了模型的推理和理解能力。</font></li>
<li><font color = black size = 4><strong>应用场景适应性受限：</strong> LLM 需在多样化的应用场景中保持高效和准确，但单一模型可能难以全面适应所有场景。RAG 使得 LLM 能够通过检索对应应用场景数据的方式，灵活适应问答系统、推荐系统等多种应用场景。</font></li>
<li><font color = black size = 4><strong>长文本处理能力较弱：</strong> LLM 在理解和生成长篇内容时受限于有限的上下文窗口，且必须按顺序处理内容，输入越长，速度越慢。RAG 通过检索和整合长文本信息，强化了模型对长上下文的理解和生成，有效突破了输入长度的限制，同时降低了调用成本，并提升了整体的处理效率。</font></li>
</ul>
<p><font color = black size = 4>为了解决大型语言模型在生成文本时面临的一系列挑战，提高模型的性能和输出质量，研究人员提出了一种新的模型架构：<strong>检索增强生成（Retrieval-Augmented Generation, RAG）</strong>。该架构巧妙地<strong>整合了从庞大知识库中检索到的相关信息，并以此为基础，指导大型语言模型生成更为精确的答案</strong>，从而显著提升了回答的准确性与深度。</font></p>
<h2 id="RAG的工作流程"><a href="#RAG的工作流程" class="headerlink" title="RAG的工作流程"></a>RAG的工作流程</h2><p><font color = black size = 4>RAG 是一个完整的系统，其工作流程可以简单地分为<strong>数据处理</strong>、<strong>检索</strong>、<strong>增强</strong>和<strong>生成</strong>四个阶段：</font></p>
<p><img src="https://raw.githubusercontent.com/phioenx/blog-img/main/blog-img/2.drawio.png"></p>
<p><font color = black size = 4>💾<strong>数据处理阶段：</strong></font></p>
<ul>
<li><font color = black size = 4>对原始数据进行清洗和处理</font></li>
<li><font color = black size = 4>将处理后的数据转化为检索模型可以使用的格式</font></li>
<li><font color = black size = 4>将处理后的数据存储在对应的数据库中。</font></li>
</ul>
<p><font color = black size = 4>💻<strong>检索阶段：</strong></font></p>
<ul>
<li><font color = black size = 4>将用户的问题输入到检索系统中，从数据库中检索相关信息。</font></li>
</ul>
<p><font color = black size = 4>🖱️<strong>增强阶段：</strong></font></p>
<ul>
<li><font color = black size = 4>对检索到的信息进行处理和增强，以便生成模型可以更好地理解和使用。</font></li>
</ul>
<p><font color = black size = 4>💿<strong>生成阶段：</strong></font></p>
<ul>
<li><font color = black size = 4>将增强后的信息输入到生成模型中，生成模型根据这些信息生成答案。</font></li>
</ul>
<h2 id="RAG-vs-Finetune"><a href="#RAG-vs-Finetune" class="headerlink" title="RAG vs Finetune"></a>RAG vs Finetune</h2><p><font color = black size = 4>在提升大语言模型效果中，RAG 和 微调（Finetune）是两种主流的方法。</font></p>
<p><font color = black size = 4><strong>微调</strong>: 通过在特定数据集上进一步训练大语言模型，来提升模型在特定任务上的表现。RAG和微调的对比可以参考下表：</font></p>
<table>
<thead>
<tr>
<th>特征比较</th>
<th>RAG</th>
<th>微调</th>
</tr>
</thead>
<tbody><tr>
<td>知识更新</td>
<td>直接更新检索知识库，无需重新训练。信息更新成本低，适合动态变化的数据。</td>
<td>通常需要重新训练来保持知识和数据的更新。更新成本高，适合静态数据。</td>
</tr>
<tr>
<td>外部知识</td>
<td>擅长利用外部资源，特别适合处理文档或其他结构化&#x2F;非结构化数据库。</td>
<td>将外部知识学习到 LLM 内部。</td>
</tr>
<tr>
<td>数据处理</td>
<td>对数据的处理和操作要求极低。</td>
<td>依赖于构建高质量的数据集，有限的数据集可能无法显著提高性能。</td>
</tr>
<tr>
<td>模型定制</td>
<td>侧重于信息检索和融合外部知识，但可能无法充分定制模型行为或写作风格。</td>
<td>可以根据特定风格或术语调整 LLM 行为、写作风格或特定领域知识。</td>
</tr>
<tr>
<td>可解释性</td>
<td>可以追溯到具体的数据来源，有较好的可解释性和可追踪性。</td>
<td>黑盒子，可解释性相对较低。</td>
</tr>
<tr>
<td>计算资源</td>
<td>需要额外的资源来支持检索机制和数据库的维护。</td>
<td>依赖高质量的训练数据集和微调目标，对计算资源的要求较高。</td>
</tr>
<tr>
<td>推理延迟</td>
<td>增加了检索步骤的耗时</td>
<td>单纯 LLM 生成的耗时</td>
</tr>
<tr>
<td>降低幻觉</td>
<td>通过检索到的真实信息生成回答，降低了产生幻觉的概率。</td>
<td>模型学习特定领域的数据有助于减少幻觉，但面对未见过的输入时仍可能出现幻觉。</td>
</tr>
<tr>
<td>伦理隐私</td>
<td>检索和使用外部数据可能引发伦理和隐私方面的问题。</td>
<td>训练数据中的敏感信息需要妥善处理</td>
</tr>
</tbody></table>
<h1 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h1><p><font color = black size = 4>ChatGPT 的巨大成功激发了越来越多的开发者兴趣，他们希望利用 OpenAI 提供的 API 或者私有化模型，来开发基于大型语言模型的应用程序。尽管大型语言模型的调用相对简单，但要创建完整的应用程序，仍然需要大量的定制开发工作，包括 API 集成、互动逻辑、数据存储等等。</font></p>
<p><font color = black size = 4>为了解决这个问题，从 2022 年开始，许多机构和个人相继推出了多个开源项目，旨在<strong>帮助开发者们快速构建基于大型语言模型的端到端应用程序或工作流程</strong>。其中一个备受关注的项目就是 LangChain 框架。</font></p>
<p><font color = black size = 4><strong>LangChain 框架是一个开源工具，充分利用了大型语言模型的强大能力，以便开发各种下游应用。它的目标是为各种大型语言模型应用提供通用接口，从而简化应用程序的开发流程</strong>。具体来说，LangChain 框架可以实现数据感知和环境互动，也就是说，它能够让语言模型与其他数据来源连接，并且允许语言模型与其所处的环境进行互动。</font></p>
<p><font color = black size = 4>利用 LangChain 框架，我们可以轻松地构建如下所示的 RAG 应用。在下图中，每个椭圆形代表了 LangChain 的一个模块，例如数据收集模块或预处理模块。每个矩形代表了一个数据状态，例如原始数据或预处理后的数据。箭头表示数据流的方向，从一个模块流向另一个模块。在每一步中，LangChain 都可以提供对应的解决方案，帮助我们处理各种任务。</font></p>
<p><img src="https://raw.githubusercontent.com/phioenx/blog-img/main/blog-img/C1-3-langchain.png"></p>
<h2 id="LangChain的核心组件"><a href="#LangChain的核心组件" class="headerlink" title="LangChain的核心组件"></a>LangChain的核心组件</h2><p><font color = black size = 4>LangChian 作为一个大语言模型开发框架，可以将 LLM 模型（对话模型、embedding 模型等）、向量数据库、交互层 Prompt、外部知识、外部代理工具整合到一起，进而可以自由构建 LLM 应用。 LangChain 主要由以下 6 个核心组件组成:</font></p>
<ul>
<li><font color = black size = 4><strong>模型输入&#x2F;输出（Model I&#x2F;O）</strong>：与语言模型交互的接口</font></li>
<li><font color = black size = 4><strong>数据连接（Data connection）</strong>：与特定应用程序的数据进行交互的接口</font></li>
<li><font color = black size = 4><strong>链（Chains）</strong>：将组件组合实现端到端应用。比如后续我们会将搭建检索问答链来完成检索问答。</font></li>
<li><font color = black size = 4><strong>记忆（Memory）</strong>：用于链的多次运行之间持久化应用程序状态；</font></li>
<li><font color = black size = 4><strong>代理（Agents）</strong>：扩展模型的推理能力。用于复杂的应用的调用序列；</font></li>
<li><font color = black size = 4><strong>回调（Callbacks）</strong>：扩展模型的推理能力。用于复杂的应用的调用序列；</font></li>
</ul>
<p><font color = black size = 4>在开发过程中，我们可以根据自身需求灵活地进行组合。</font></p>
<h2 id="LangChain的生态"><a href="#LangChain的生态" class="headerlink" title="LangChain的生态"></a>LangChain的生态</h2><p><font color = black size = 4><strong>LangChain Community</strong>: 专注于第三方集成，极大地丰富了 LangChain 的生态系统，使得开发者可以更容易地构建复杂和强大的应用程序，同时也促进了社区的合作和共享。</font></p>
<p><font color = black size = 4><strong>LangChain Core</strong>: LangChain 框架的核心库、核心组件，提供了基础抽象和 LangChain 表达式语言（LCEL），提供基础架构和工具，用于构建、运行和与 LLM 交互的应用程序，为 LangChain 应用程序的开发提供了坚实的基础。我们后续会用到的处理文档、格式化 prompt、输出解析等都来自这个库。</font></p>
<p><font color = black size = 4><strong>LangChain CLI</strong>: 命令行工具，使开发者能够通过终端与 LangChain 框架交互，执行项目初始化、测试、部署等任务。提高开发效率，让开发者能够通过简单的命令来管理整个应用程序的生命周期。</font></p>
<p><font color = black size = 4><strong>LangServe</strong>: 部署服务，用于将 LangChain 应用程序部署到云端，提供可扩展、高可用的托管解决方案，并带有监控和日志功能。简化部署流程，让开发者可以专注于应用程序的开发，而不必担心底层的基础设施和运维工作。</font></p>
<p><font color = black size = 4><strong>LangSmith</strong>: 开发者平台，专注于 LangChain 应用程序的开发、调试和测试，提供可视化界面和性能分析工具，旨在帮助开发者提高应用程序的质量，确保它们在部署前达到预期的性能和稳定性标准。</font></p>
<h1 id="大模型开发"><a href="#大模型开发" class="headerlink" title="大模型开发"></a>大模型开发</h1><p><font color = black size = 4>我们将开发<strong>以大语言模型为功能核心、通过大语言模型的强大理解能力和生成能力、结合特殊的数据或业务逻辑来提供独特功能的应用</strong>称为<strong>大模型开发</strong>。开发大模型相关应用，其技术核心点虽然在大语言模型上，但一般通过调用 API 或开源模型来实现核心的理解与生成，通过 Prompt Enginnering 来实现大语言模型的控制，因此，虽然大模型是深度学习领域的集大成之作，大模型开发却更多是一个<strong>工程问题</strong>。</font></p>
<p><font color = black size = 4>在大模型开发中，我们一般不会去大幅度改动模型，而是<strong>将大模型作为一个调用工具，通过 Prompt Engineering、数据工程、业务逻辑分解等手段来充分发挥大模型能力，适配应用任务</strong>，而不会将精力聚焦在优化模型本身上。因此，作为大模型开发的初学者，我们并不需要深研大模型内部原理，而更需要掌握使用大模型的实践技巧。</font></p>
<h2 id="大模型开发的一般流程"><a href="#大模型开发的一般流程" class="headerlink" title="大模型开发的一般流程"></a>大模型开发的一般流程</h2><p><font color = black size = 4>我们一般可以将大模型开发分解为以下几个流程：</font></p>
<p><img src="https://github.com/datawhalechina/llm-universe/raw/main/figures/C1-4-LLM_developing_whole.png"></p>
<ul>
<li><font color = black size = 4>1️⃣<strong>确定目标</strong>。在进行开发前，我们首先需要确定开发的目标，即要开发的应用的应用场景、目标人群、核心价值。对于个体开发者或小型开发团队而言，一般应先设定最小化目标，从构建一个 MVP（最小可行性产品）开始，逐步进行完善和优化。</font></li>
<li><font color = black size = 4>2️⃣<strong>设计功能</strong>。在确定开发目标后，需要设计本应用所要提供的功能，以及每一个功能的大体实现逻辑。虽然我们通过使用大模型来简化了业务逻辑的拆解，但是越清晰、深入的业务逻辑理解往往也能带来更好的 Prompt 效果。同样，对于个体开发者或小型开发团队来说，首先要确定应用的核心功能，然后延展设计核心功能的上下游功能；例如，我们想打造一款个人知识库助手，那么核心功能就是结合个人知识库内容进行问题的回答，那么其上游功能的用户上传知识库、下游功能的用户手动纠正模型回答就是我们也必须要设计实现的子功能。</font></li>
<li><font color = black size = 4>3️⃣<strong>搭建整体架构</strong>。目前，绝大部分大模型应用都是采用的特定数据库 + Prompt + 通用大模型的架构。我们需要针对我们所设计的功能，搭建项目的整体架构，实现从用户输入到应用输出的全流程贯通。一般来说，我们推荐基于 LangChain 框架进行开发。LangChain 提供了 Chain、Tool 等架构的实现，我们可以基于 LangChain 进行个性化定制，实现从用户输入到数据库再到大模型最后输出的整体架构连接。</font></li>
<li><font color = black size = 4>4️⃣<strong>搭建数据库</strong>。个性化大模型应用需要有个性化数据库进行支撑。由于大模型应用需要进行向量语义检索，一般使用诸如 Chroma 的向量数据库。在该步骤中，我们需要收集数据并进行预处理，再向量化存储到数据库中。数据预处理一般包括从多种格式向纯文本的转化，例如 PDF、MarkDown、HTML、音视频等，以及对错误数据、异常数据、脏数据进行清洗。完成预处理后，需要进行切片、向量化构建出个性化数据库。</font></li>
<li><font color = black size = 4>5️⃣<strong>Prompt Engineering</strong>。优质的 Prompt 对大模型能力具有极大影响，我们需要逐步迭代构建优质的 Prompt Engineering 来提升应用性能。在该步中，我们首先应该明确 Prompt 设计的一般原则及技巧，构建出一个来源于实际业务的小型验证集，基于小型验证集设计满足基本要求、具备基本能力的 Prompt。</font></li>
<li><font color = black size = 4>6️⃣<strong>验证迭代</strong>。验证迭代在大模型开发中是极其重要的一步，一般指通过不断发现 Bad Case 并针对性改进 Prompt Engineering 来提升系统效果、应对边界情况。在完成上一步的初始化 Prompt 设计后，我们应该进行实际业务测试，探讨边界情况，找到 Bad Case，并针对性分析 Prompt 存在的问题，从而不断迭代优化，直到达到一个较为稳定、可以基本实现目标的 Prompt 版本。</font></li>
<li><font color = black size = 4>7️⃣<strong>前后端搭建</strong>。完成 Prompt Engineering 及其迭代优化之后，我们就完成了应用的核心功能，可以充分发挥大语言模型的强大能力。接下来我们需要搭建前后端，设计产品页面，让我们的应用能够上线成为产品。前后端开发是非常经典且成熟的领域，此处就不再赘述，我们采用 Gradio 和 Streamlit，可以帮助个体开发者迅速搭建可视化页面实现 Demo 上线。</font></li>
<li><font color = black size = 4>8️⃣<strong>体验优化</strong>。在完成前后端搭建之后，应用就可以上线体验了。接下来就需要进行长期的用户体验跟踪，记录 Bad Case 与用户负反馈，再针对性进行优化即可。</font></li>
</ul>
<h2 id="搭建-LLM-项目的流程简析（以知识库助手为例）"><a href="#搭建-LLM-项目的流程简析（以知识库助手为例）" class="headerlink" title="搭建 LLM 项目的流程简析（以知识库助手为例）"></a>搭建 LLM 项目的流程简析（以知识库助手为例）</h2><p><font color = black size = 4>🥝<strong>项目目标：</strong> 基于个人知识库的问答助手</font></p>
<p><font color = black size = 4>🍆<strong>核心功能：</strong></font></p>
<ul>
<li><font color = black size = 4>将爬取并总结的 MarkDown 文件及用户上传文档向量化，并创建知识库；</font></li>
<li><font color = black size = 4>选择知识库，检索用户提问的知识片段；</font></li>
<li><font color = black size = 4>选择知识库，检索用户提问的知识片段；</font></li>
<li><font color = black size = 4>流式回复；</font></li>
<li><font color = black size = 4>历史对话记录</font></li>
</ul>
<p><font color = black size = 4>🌽<strong>确定技术架构和工具：</strong></font></p>
<ul>
<li><font color = black size = 4><strong>框架</strong>：LangChain</font></li>
<li><font color = black size = 4><strong>Embedding 模型</strong>：GPT、智谱、<a target="_blank" rel="noopener" href="https://huggingface.co/moka-ai/m3e-base">M3E</a></font></li>
<li><font color = black size = 4><strong>数据库</strong>：Chroma</font></li>
<li><font color = black size = 4><strong>大模型</strong>：GPT、讯飞星火、文心一言、GLM 等</font></li>
<li><font color = black size = 4><strong>前端</strong>：Gradio 和 Streamlit</font></li>
</ul>
<p><font color = black size = 4>🍙<strong>数据准备与向量知识库构建：</strong></font></p>
<p><font color = black size = 4>本项目实现原理如下图所示：<strong>加载本地文档 -&gt; 读取文本 -&gt; 文本分割 -&gt; 文本向量化 -&gt; question 向量化 -&gt; 在文本向量中匹配出与问句向量最相似的 top k 个 -&gt; 匹配出的文本作为上下文和问题一起添加到 Prompt 中 -&gt; 提交给 LLM 生成回答。</strong></font></p>
<p><img src="https://raw.githubusercontent.com/phioenx/blog-img/main/blog-img/image-20251031091931486.png"></p>
<p><font color = black size = 4>1️⃣<strong>收集和整理用户提供的文档</strong></font></p>
<ul>
<li><font color = black size = 4>用户常用文档格式有 PDF、TXT、MD 等，首先，我们可以使用 LangChain 的文档加载器模块方便地加载用户提供的文档，或者使用一些成熟的 Python 包进行读取。</font></li>
<li><font color = black size = 4>由于目前大模型使用 token 的限制，我们需要对读取的文本进行切分，将较长的文本切分为较小的文本，这时一段文本就是一个单位的知识。</font></li>
</ul>
<p><font color = black size = 4>2️⃣<strong>将文档词向量化</strong></font></p>
<ul>
<li><font color = black size = 4>使用<strong>文本嵌入(Embeddings)技术</strong>对分割后的文档进行向量化，使语义相似的文本片段具有接近的向量表示。然后，存入向量数据库，完成**索引(index)**的创建。</font></li>
<li><font color = black size = 4>利用向量数据库对各文档片段进行索引，可以实现快速检索。</font></li>
</ul>
<p><font color = black size = 4>3️⃣<strong>将向量化后的文档导入 Chroma 知识库，建立知识库索引</strong></font></p>
<ul>
<li><font color = black size = 4>Langchain 集成了超过 30 个不同的向量数据库。Chroma 数据库轻量级且数据存储在内存中，这使得它非常容易启动和开始使用。</font></li>
<li><font color = black size = 4>将用户知识库内容经过 Embedding 存入向量数据库，然后用户每一次提问也会经过 Embedding，利用向量相关性算法（例如余弦算法）找到最匹配的几个知识库片段，将这些知识库片段作为上下文，与用户问题一起作为 Prompt 提交给 LLM 回答。</font></li>
</ul>
<p><font color = black size = 4>4️⃣<strong>大模型集成与API连接</strong></font></p>
<ul>
<li><font color = black size = 4>集成 GPT、星火、文心、GLM 等大模型，配置 API 连接。</font></li>
<li><font color = black size = 4>编写代码，实现与大模型 API 的交互，以便获取问题回答。</font></li>
</ul>
<p><font color = black size = 4>5️⃣<strong>核心功能实现</strong></font></p>
<ul>
<li><font color = black size = 4>构建 Prompt Engineering，实现大模型回答功能，根据用户提问和知识库内容生成回答。</font></li>
<li><font color = black size = 4>实现流式回复，允许用户进行多轮对话。</font></li>
<li><font color = black size = 4>添加历史对话记录功能，保存用户与助手的交互历史。</font></li>
</ul>
<p><font color = black size = 4>6️⃣<strong>核心功能迭代优化</strong></font></p>
<ul>
<li><font color = black size = 4>进行验证评估，收集 Bad Case。</font></li>
<li><font color = black size = 4>根据 Bad Case 迭代优化核心功能实现。</font></li>
</ul>
<p><font color = black size = 4>7️⃣<strong>前端与用户交互界面开发</strong></font></p>
<ul>
<li><font color = black size = 4>使用 Gradio 和 Streamlit 搭建前端界面。</font></li>
<li><font color = black size = 4>实现用户上传文档、创建知识库的功能。</font></li>
<li><font color = black size = 4>设计用户界面，包括问题输入、知识库选择、历史记录展示等。</font></li>
</ul>
<p><font color = black size = 4>8️⃣<strong>部署测试与上线</strong></font></p>
<ul>
<li><font color = black size = 4>部署问答助手到服务器或云平台，确保可在互联网上访问。</font></li>
<li><font color = black size = 4>进行生产环境测试，确保系统稳定。</font></li>
<li><font color = black size = 4>上线并向用户发布。</font></li>
</ul>
<p><font color = black size = 4>9️⃣<strong>维护与持续改进</strong></font></p>
<ul>
<li><font color = black size = 4>监测系统性能和用户反馈，及时处理问题。</font></li>
<li><font color = black size = 4>定期更新知识库，添加新的文档和信息。</font></li>
<li><font color = black size = 4>收集用户需求，进行系统改进和功能扩展。</font></li>
</ul>
<p><font color = black size = 4>整个流程将确保项目从规划、开发、测试到上线和维护都能够顺利进行，为用户提供高质量的基于个人知识库的问答助手。</font></p>
<p><font color = black size = 4>【<strong>参考内容</strong>】：</font></p>
<p><font color = black size = 4><a target="_blank" rel="noopener" href="https://github.com/datawhalechina/llm-universe/">llm-universe：大型语言模型 LLM 介绍</a></font></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">PhoenixPeng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/10/30/4.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%89%EF%BC%89/">http://example.com/2025/10/30/4.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%89%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">哈基鹏的博客🐦</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="/img/cover4.jpg" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/10/31/5.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E5%9B%9B%EF%BC%89/" title="哈基鹏的大模型之旅（四）"><img class="cover" src="/img/cover5.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">哈基鹏的大模型之旅（四）</div></div><div class="info-2"><div class="info-item-1">大模型微调专题。</div></div></div></a><a class="pagination-related" href="/2025/10/29/3.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%BA%8C%EF%BC%89/" title="哈基鹏的大模型之旅（二）"><img class="cover" src="/img/cover3.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">哈基鹏的大模型之旅（二）</div></div><div class="info-2"><div class="info-item-1">Transformer的架构和基本原理介绍，并介绍如何搭建一个Transformer。</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/10/29/3.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%BA%8C%EF%BC%89/" title="哈基鹏的大模型之旅（二）"><img class="cover" src="/img/cover3.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-29</div><div class="info-item-2">哈基鹏的大模型之旅（二）</div></div><div class="info-2"><div class="info-item-1">Transformer的架构和基本原理介绍，并介绍如何搭建一个Transformer。</div></div></div></a><a class="pagination-related" href="/2025/10/28/2.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%80%EF%BC%89/" title="哈基鹏的大模型之旅（一）"><img class="cover" src="/img/cover2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-28</div><div class="info-item-2">哈基鹏的大模型之旅（一）</div></div><div class="info-2"><div class="info-item-1">大语言模型LLM介绍，包括大语言模型的定义、概述了OpenAI、Claude、Gemini、DeepSeek等系列模型的发展路程。</div></div></div></a><a class="pagination-related" href="/2025/10/31/5.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E5%9B%9B%EF%BC%89/" title="哈基鹏的大模型之旅（四）"><img class="cover" src="/img/cover5.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-31</div><div class="info-item-2">哈基鹏的大模型之旅（四）</div></div><div class="info-2"><div class="info-item-1">大模型微调专题。</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">PhoenixPeng</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/phioenx" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到哈基鹏的小站</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%EF%BC%88RAG%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">检索增强生成（RAG）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#RAG%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">1.1.</span> <span class="toc-text">RAG的工作流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RAG-vs-Finetune"><span class="toc-number">1.2.</span> <span class="toc-text">RAG vs Finetune</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#LangChain"><span class="toc-number">2.</span> <span class="toc-text">LangChain</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#LangChain%E7%9A%84%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="toc-number">2.1.</span> <span class="toc-text">LangChain的核心组件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LangChain%E7%9A%84%E7%94%9F%E6%80%81"><span class="toc-number">2.2.</span> <span class="toc-text">LangChain的生态</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91"><span class="toc-number">3.</span> <span class="toc-text">大模型开发</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B"><span class="toc-number">3.1.</span> <span class="toc-text">大模型开发的一般流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%90%AD%E5%BB%BA-LLM-%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%B5%81%E7%A8%8B%E7%AE%80%E6%9E%90%EF%BC%88%E4%BB%A5%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B%E4%B8%BA%E4%BE%8B%EF%BC%89"><span class="toc-number">3.2.</span> <span class="toc-text">搭建 LLM 项目的流程简析（以知识库助手为例）</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/10/31/5.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E5%9B%9B%EF%BC%89/" title="哈基鹏的大模型之旅（四）"><img src="/img/cover5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="哈基鹏的大模型之旅（四）"/></a><div class="content"><a class="title" href="/2025/10/31/5.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E5%9B%9B%EF%BC%89/" title="哈基鹏的大模型之旅（四）">哈基鹏的大模型之旅（四）</a><time datetime="2025-10-31T07:08:19.000Z" title="发表于 2025-10-31 15:08:19">2025-10-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/30/4.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%89%EF%BC%89/" title="哈基鹏的大模型之旅（三）"><img src="/img/cover4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="哈基鹏的大模型之旅（三）"/></a><div class="content"><a class="title" href="/2025/10/30/4.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%89%EF%BC%89/" title="哈基鹏的大模型之旅（三）">哈基鹏的大模型之旅（三）</a><time datetime="2025-10-30T08:03:26.000Z" title="发表于 2025-10-30 16:03:26">2025-10-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/29/3.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%BA%8C%EF%BC%89/" title="哈基鹏的大模型之旅（二）"><img src="/img/cover3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="哈基鹏的大模型之旅（二）"/></a><div class="content"><a class="title" href="/2025/10/29/3.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%BA%8C%EF%BC%89/" title="哈基鹏的大模型之旅（二）">哈基鹏的大模型之旅（二）</a><time datetime="2025-10-29T07:14:36.000Z" title="发表于 2025-10-29 15:14:36">2025-10-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/28/2.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%80%EF%BC%89/" title="哈基鹏的大模型之旅（一）"><img src="/img/cover2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="哈基鹏的大模型之旅（一）"/></a><div class="content"><a class="title" href="/2025/10/28/2.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%80%EF%BC%89/" title="哈基鹏的大模型之旅（一）">哈基鹏的大模型之旅（一）</a><time datetime="2025-10-28T02:57:14.000Z" title="发表于 2025-10-28 10:57:14">2025-10-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/28/1.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84butterfly%E9%AD%94%E6%94%B9%E8%AE%B0%E5%BD%95/" title="哈基鹏的butterfly魔改记录"><img src="/img/cover1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="哈基鹏的butterfly魔改记录"/></a><div class="content"><a class="title" href="/2025/10/28/1.%E5%93%88%E5%9F%BA%E9%B9%8F%E7%9A%84butterfly%E9%AD%94%E6%94%B9%E8%AE%B0%E5%BD%95/" title="哈基鹏的butterfly魔改记录">哈基鹏的butterfly魔改记录</a><time datetime="2025-10-28T02:04:09.000Z" title="发表于 2025-10-28 10:04:09">2025-10-28</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By PhoenixPeng</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.1</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.1"></script><script src="/js/main.js?v=5.5.1"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        loader: {
          load: [
            // Four font extension packages (optional)
            //- '[tex]/bbm',
            //- '[tex]/bboldx',
            //- '[tex]/dsfont',
            '[tex]/mhchem'
          ],
          paths: {
            'mathjax-newcm': '[mathjax]/../@mathjax/mathjax-newcm-font',

            //- // Four font extension packages (optional)
            //- 'mathjax-bbm-extension': '[mathjax]/../@mathjax/mathjax-bbm-font-extension',
            //- 'mathjax-bboldx-extension': '[mathjax]/../@mathjax/mathjax-bboldx-font-extension',
            //- 'mathjax-dsfont-extension': '[mathjax]/../@mathjax/mathjax-dsfont-font-extension',
            'mathjax-mhchem-extension': '[mathjax]/../@mathjax/mathjax-mhchem-font-extension'
          }
        },
        output: {
          font: 'mathjax-newcm',
        },
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
          packages: {
            '[+]': [
              'mhchem'
            ]
          }
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          menuOptions: {
            settings: {
              enrich: false  // Turn off Braille and voice narration text automatic generation
            }
          },
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@4.0.0/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax src="https://unpkg.com/oh-my-live2d"></script><script>const oml2d = OML2D.loadOml2d({dockedPosition:"left",mobileDisplay:false,models:[{"path":"/live2d-models/rem/model.json","position":[50,50],"scale":0.15,"stageStyle":{"width":250,"height":250},"mobilePosition":[10,23],"mobileScale":0.1,"mobileStageStyle":{"width":180,"height":166},"motionPreloadStrategy":"ALL"},{"path":"/live2d-models/hailunna_4/hailunna_4.model3.json","position":[-50,0],"scale":0.08,"stageStyle":{"width":350,"height":350},"mobilePosition":[-10,23],"mobileScale":0.08,"mobileStageStyle":{"width":180,"height":166},"motionPreloadStrategy":"IDLE"}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:false,tips:{style: {"width":230,"height":120,"left":"calc(50% - 20px)","top":"-100px"},mobileStyle: {"width":180,"height":80,"left":"calc(50% - 30px)","top":"-100px"},idleTips:{interval:3600,message:["你好呀，我是哈基鹏~","欢迎来到我的小站~"]}}});</script><!-- hexo injector body_end end --></body></html>